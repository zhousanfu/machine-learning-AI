{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç§‘å¤§è®¯é£ åŸºäºè®ºæ–‡æ‘˜è¦çš„æ–‡æœ¬åˆ†ç±»ä¸å…³é”®è¯æŠ½å–æŒ‘æˆ˜èµ›[ğŸ”—](https://challenge.xfyun.cn/topic/info?type=abstract-of-the-paper&option=ssgy&ch=F5ZbQiB)\n",
    "\n",
    "ä¸€ã€èµ›äº‹èƒŒæ™¯\n",
    "\n",
    "åŒ»å­¦é¢†åŸŸçš„æ–‡çŒ®åº“ä¸­è•´å«äº†ä¸°å¯Œçš„ç–¾ç—…è¯Šæ–­å’Œæ²»ç–—ä¿¡æ¯ï¼Œå¦‚ä½•é«˜æ•ˆåœ°ä»æµ·é‡æ–‡çŒ®ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œè¿›è¡Œç–¾ç—…è¯Šæ–­å’Œæ²»ç–—æ¨èï¼Œå¯¹äºä¸´åºŠåŒ»ç”Ÿå’Œç ”ç©¶äººå‘˜å…·æœ‰é‡è¦æ„ä¹‰ã€‚\n",
    "\n",
    "äºŒã€èµ›äº‹ä»»åŠ¡\n",
    "\n",
    "æœ¬ä»»åŠ¡åˆ†ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼š\n",
    "æœºå™¨é€šè¿‡å¯¹è®ºæ–‡æ‘˜è¦ç­‰ä¿¡æ¯çš„ç†è§£ï¼Œåˆ¤æ–­è¯¥è®ºæ–‡æ˜¯å¦å±äºåŒ»å­¦é¢†åŸŸçš„æ–‡çŒ®ã€‚\n",
    "æå–å‡ºè¯¥è®ºæ–‡å…³é”®è¯ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¼ ç»ŸNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒçš„BERTæ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# å®šä¹‰åˆ†ç±»æ¨¡å‹\n",
    "class PaperClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PaperClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768, 2)  # 768æ˜¯BERTæ¨¡å‹çš„éšè—å±‚å¤§å°\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        _, pooled_output = self.bert(text)\n",
    "        output = self.fc(pooled_output)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "# å®šä¹‰å…³é”®è¯æå–æ¨¡å‹\n",
    "class KeywordExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeywordExtractor, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768, 1)  # 768æ˜¯BERTæ¨¡å‹çš„éšè—å±‚å¤§å°\n",
    "        \n",
    "    def forward(self, text):\n",
    "        _, pooled_output = self.bert(text)\n",
    "        output = self.fc(pooled_output)\n",
    "        return output\n",
    "\n",
    "# é¢„å¤„ç†æ•°æ®\n",
    "def preprocess_data():\n",
    "    # å®šä¹‰å­—æ®µ\n",
    "    TEXT = Field(sequential=True, tokenize=tokenizer.tokenize, lower=True, include_lengths=True)\n",
    "    LABEL = Field(sequential=False, use_vocab=False)\n",
    "    KEYWORDS = Field(sequential=True, tokenize='spacy', lower=True)\n",
    "    \n",
    "    # åŠ è½½æ•°æ®é›†\n",
    "    train_data, test_data = TabularDataset.splits(\n",
    "        path='data',\n",
    "        train='train.csv',\n",
    "        test='test.csv',\n",
    "        format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL), ('keywords', KEYWORDS)]\n",
    "    )\n",
    "    \n",
    "    # æ„å»ºè¯æ±‡è¡¨\n",
    "    TEXT.build_vocab(train_data)\n",
    "    KEYWORDS.build_vocab(train_data)\n",
    "    \n",
    "    # åˆ›å»ºè¿­ä»£å™¨\n",
    "    train_iterator, test_iterator = BucketIterator.splits(\n",
    "        (train_data, test_data),\n",
    "        batch_size=32,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        sort_within_batch=True\n",
    "    )\n",
    "    \n",
    "    return train_iterator, test_iterator\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "def train_model(model, train_iterator):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    classifier_criterion = nn.CrossEntropyLoss()\n",
    "    extractor_criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for batch in train_iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            labels = batch.label\n",
    "            keywords = torch.tensor([getattr(batch, 'keywords')]).squeeze().T.float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            class_output, extract_output = model(text)\n",
    "            classifier_loss = classifier_criterion(class_output, labels)\n",
    "            extractor_loss = extractor_criterion(extract_output, keywords)\n",
    "            loss = classifier_loss + extractor_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    indexed_tokens = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        class_output, extract_output = model(tokens_tensor)\n",
    "        predicted_label = torch.argmax(class_output, dim=1)\n",
    "        predicted_keywords = [token for token, score in zip(tokenizer.tokenize(sentence), extract_output[0]) if score > 0]\n",
    "        \n",
    "    return predicted_label.item(), predicted_keywords\n",
    "\n",
    "# ä¸»å‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    train_iterator, _ = preprocess_data()\n",
    "    \n",
    "    classifier_model = PaperClassifier()\n",
    "    keyword_model = KeywordExtractor()\n",
    "    model = nn.ModuleList([classifier_model, keyword_model])\n",
    "    \n",
    "    train_model(model, train_iterator)\n",
    "    \n",
    "    example_sentence = \"This is a medical paper about cancer detection.\"\n",
    "    predicted_label, predicted_keywords = predict(model, example_sentence)\n",
    "    \n",
    "    if predicted_label == 1:\n",
    "        print(\"1\")\n",
    "    else:\n",
    "        print(\"0\")\n",
    "    \n",
    "    print(\"æå–çš„å…³é”®è¯ï¼š\", predicted_keywords)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
