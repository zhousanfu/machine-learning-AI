{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhousanfu/machine-learning-demo/blob/master/LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbEDIhXr5QYP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence_transformers sentencepiece cpm_kernels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu"
      ],
      "metadata": {
        "id": "g5uDtyPy8M7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -i pypi.douban.com/simple --trusted-host pypi.douban.com"
      ],
      "metadata": {
        "id": "y1YCya_S-rOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatglm"
      ],
      "metadata": {
        "id": "7uiRt-JmBtjz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbBCts3O3mX8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "class chatGLM():\n",
        "    def __init__(self, model_name, quantization_bit=4) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).half().cuda().eval()\n",
        "        self.model = self.model.quantize(quantization_bit)\n",
        "\n",
        "    def __call__(self, prompt, history) -> Any:\n",
        "        response, history = self.model.chat(self.tokenizer , prompt, history=history) # ËøôÈáåÊºîÁ§∫Êú™‰ΩøÁî®ÊµÅÂºèÊé•Âè£. stream_chat()\n",
        "        return response, history\n",
        "\n",
        "llm = chatGLM(model_name=\"THUDM/chatglm-6B-int4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response, history = llm(prompt=\"‰Ω†Â•Ω\", history=[])\n",
        "print(\"response: %s\"%response)\n",
        "response, history = llm(prompt=\"ÊàëÊúÄËøëÊúâÁÇπÂ§±Áú†ÊÄé‰πàÂäû?\", history=history)\n",
        "print(\"response: %s\"%response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8MrQIdOBhtc",
        "outputId": "924f72e6-67c1-4934-efe0-587ffc09214a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.THUDM.chatglm-6B-int4.02a065cf2797029c036a02cac30f1da1a9bc49a3.modeling_chatglm:The dtype of attention mask (torch.int64) is not bool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response: ‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ\n",
            "response: Â§±Áú†ÁöÑËØùÂèØ‰ª•Â∞ùËØï‰∏ãËø∞ÊñπÊ≥ïËøõË°åÊîπÂñÑÔºö\n",
            "1. Áù°ÂâçÊîæÊùæÔºöÂú®Áù°ÂâçÊîæÊùæË∫´ÂøÉÔºå‰æãÂ¶ÇËøõË°åÊ∑±ÂëºÂê∏„ÄÅÂÜ•ÊÉ≥„ÄÅÊ≥°‰∏™ÁÉ≠Ê∞¥Êæ°ÊàñÂê¨ÊüîÂíåÁöÑÈü≥‰πêÁ≠â„ÄÇ\n",
            "2. Âª∫Á´ãËßÑÂæãÁöÑÁù°Áú†Êó∂Èó¥ÔºöÂ∞ΩÈáèÂú®Âêå‰∏ÄÊó∂Èó¥ÂÖ•Áù°ÂíåËµ∑Â∫äÔºåÂç≥‰ΩøÂú®Âë®Êú´ÂíåÂÅáÊúü‰πüË¶Å‰øùÊåÅ‰∏ÄÂÆöÁöÑËßÑÂæã„ÄÇ\n",
            "3. ÈÅøÂÖçÂà∫ÊøÄÔºöÂú®Áù°ÂâçÈÅøÂÖçËøáÂ∫¶Âà∫ÊøÄÔºå‰æãÂ¶ÇÁúãÁîµÂ≠êÂ±èÂπï„ÄÅ‰ΩøÁî®ÁîµËÑë„ÄÅ‰ΩøÁî®ÊâãÊú∫Á≠â„ÄÇ\n",
            "4. È•ÆÈ£üË∞ÉÊï¥ÔºöÂú®Áù°ÂâçÈÅøÂÖçÊëÑÂÖ•ÂíñÂï°Âõ†„ÄÅÈÖíÁ≤æÁ≠âÂà∫ÊøÄÁâ©Ë¥®ÔºåÂèØ‰ª•ÈÄÇÂΩìÂ¢ûÂä†‰∏Ä‰∫õÊòìÊ∂àÂåñÁöÑÈ£üÁâ©Ôºå‰æãÂ¶ÇÁâõÂ•∂„ÄÅÈù¢ÂåÖÁ≠â„ÄÇ\n",
            "5. ÊîπÂñÑÁù°Áú†ÁéØÂ¢ÉÔºö‰øùÊåÅÂçßÂÆ§ÂÆâÈùô„ÄÅÈªëÊöó„ÄÅÂáâÁàΩÂíåËàíÈÄÇÔºåÂ¶ÇÊûúÊúâÂøÖË¶ÅÂèØ‰ª•‰ΩøÁî®Áù°Áú†Èù¢ÁΩ©„ÄÅËÄ≥Â°ûÁ≠âÂ∑•ÂÖ∑„ÄÇ\n",
            "‰ª•‰∏äÊòØ‰∏Ä‰∫õÊîπÂñÑÂ§±Áú†ÁöÑÊñπÊ≥ïÔºåÂ¶ÇÊûúËøô‰∫õÊñπÊ≥ï‰∏çËÉΩËß£ÂÜ≥ÊÇ®ÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•Âí®ËØ¢ÂåªÁîüÊàñ‰∏ì‰∏ö‰∫∫Â£´ÁöÑÊÑèËßÅ„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain\n",
        "\n",
        "LangChainÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®Â∏ÆÂä©ÂºÄÂèë‰∫∫Âëò‰ΩøÁî®ËØ≠Ë®ÄÊ®°ÂûãÊûÑÂª∫Á´ØÂà∞Á´ØÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂ•óÂ∑•ÂÖ∑„ÄÅÁªÑ‰ª∂ÂíåÊé•Âè£ÔºåÂèØÁÆÄÂåñÂàõÂª∫Áî±Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂíåËÅäÂ§©Ê®°ÂûãÊèê‰æõÊîØÊåÅÁöÑÂ∫îÁî®Á®ãÂ∫èÁöÑËøáÁ®ã„ÄÇLangChain ÂèØ‰ª•ËΩªÊùæÁÆ°ÁêÜ‰∏éËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∫§‰∫íÔºåÂ∞ÜÂ§ö‰∏™ÁªÑ‰ª∂ÈìæÊé•Âú®‰∏ÄËµ∑ÔºåÂπ∂ÈõÜÊàêÈ¢ùÂ§ñÁöÑËµÑÊ∫ê"
      ],
      "metadata": {
        "id": "hMURU65yCiBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ÂÆòÊñπllm‰ΩøÁî®OPENAI Êé•Âè£\n",
        "# from langchain.llms import OpenAI\n",
        "# llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "# prompt = \"‰Ω†Â•Ω\"\n",
        "# response = llm(prompt)"
      ],
      "metadata": {
        "id": "RS4PLFqgSXtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prompt\n",
        "Â°´ÂÖ•ÂÜÖÂÆπÊù•ÂºïÂØºÂ§ßÊ®°ÂûãËæìÂá∫"
      ],
      "metadata": {
        "id": "7SE976V_CuP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "template = \"\"\"‰ªÄ‰πàÊòØ{query},ËøòÊúâÂ¶Ç‰ΩïÁúüÊ≠£ÂÅöÂà∞Âπ∂ÁªÜËØ¥ÂÆûÁé∞Ê≠•È™§\"\"\"\n",
        "prompt_tem = PromptTemplate(input_variables=[\"query\"], template=template)\n",
        "prompt = prompt_tem.format(query='Èò∂Á∫ßË∑≥Ë∑É')\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FPt2QqzyCtsB",
        "outputId": "15cf7b26-7731-41e8-b2a3-f97097ddedc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‰ªÄ‰πàÊòØÈò∂Á∫ßË∑≥Ë∑É,ËøòÊúâÂ¶Ç‰ΩïÁúüÊ≠£ÂÅöÂà∞Âπ∂ÁªÜËØ¥ÂÆûÁé∞Ê≠•È™§'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains\n",
        "ÈìæÊé•Â§ö‰∏™ÁªÑ‰ª∂Â§ÑÁêÜ‰∏Ä‰∏™ÁâπÂÆöÁöÑ‰∏ãÊ∏∏‰ªªÂä°"
      ],
      "metadata": {
        "id": "4_MqGD66Di6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chains import LLMChain\n",
        "# chain = LLMChain(llm=openAI(), prompt=promptTem)\n",
        "# print(chain.run(\"‰Ω†Â•Ω\"))\n",
        "\n",
        "from langchain.chains.base import Chain\n",
        "\n",
        "\n",
        "\n",
        "class DemoChain():\n",
        "    def __init__(self, llm, prompt, history) -> None:\n",
        "        self.llm = llm\n",
        "        self.prompt = prompt\n",
        "        self.history = history\n",
        "\n",
        "    def run(self, query, history, context=None) -> Any:\n",
        "        if context is not None:\n",
        "            prompt = self.prompt.format(query=query, context=context)\n",
        "        else:\n",
        "            prompt = self.prompt.format(query=query)\n",
        "\n",
        "        response, history = self.llm(prompt, history)\n",
        "        return response, history\n",
        "\n",
        "chain = DemoChain(llm=llm, prompt=prompt_tem, history=[])\n",
        "response, history = chain.run(query=\"Èò∂Á∫ßË∑≥Ë∑É\", history=[])\n",
        "print(response, history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYEVjYq4DlrN",
        "outputId": "f2e92911-c32b-4879-ed7a-25441050d209"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Èò∂Á∫ßË∑≥Ë∑ÉÊòØÊåáÂú®‰∏Ä‰∏™Ê∏∏Êàè‰∏≠ÔºåÁé©ÂÆ∂ÈÄöËøá‰∏Ä‰∫õÊäÄÂ∑ßÂíåÁ≠ñÁï•Ôºå‰ªé‰∏Ä‰∏™ÊôÆÈÄöÁöÑÁé©ÂÆ∂Áõ¥Êé•Ë∑ÉÂèò‰∏∫È´òÁ∫ßÁé©ÂÆ∂Ôºå‰æãÂ¶Ç‰∏Ä‰∏™ÂàùÁ∫ßÁé©ÂÆ∂Âà∞È´òÁ∫ßÁé©ÂÆ∂ÁöÑÈò∂Á∫ßË∑®Ë∂ä„ÄÇ\n",
            "\n",
            "Èò∂Á∫ßË∑≥Ë∑ÉÈÄöÂ∏∏ÈúÄË¶ÅÁé©ÂÆ∂Âú®ÂàùÊúüÁßØÁ¥ØÂ§ßÈáèÁöÑÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏ÅÔºåÁÑ∂Âêé‰ΩøÁî®Ëøô‰∫õÁßØÁ¥ØÊù•Ë¥≠‰π∞Ê∏∏Êàè‰∏≠ÁöÑÈ´òÁ∫ßÁâ©ÂìÅÂíåÊäÄËÉΩÔºåÊàñËÄÖÂú®Ê∏∏Êàè‰∏≠‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫âÔºåÈÄöËøáÂáªË¥•ÂØπÊâãÊù•Ëé∑ÂæóÊõ¥Â§öÁöÑÊ∏∏ÊàèÂ∏ÅÂíåÁªèÈ™åÂÄº„ÄÇ\n",
            "\n",
            "ÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑ÉÁöÑËØ¶ÁªÜÊ≠•È™§Â¶Ç‰∏ãÔºö\n",
            "\n",
            "1. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÁßØÁ¥ØÂ§ßÈáèÁöÑÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏Å„ÄÇÂèØ‰ª•ÈÄöËøáÂÆåÊàêÊ∏∏Êàè‰∏≠ÁöÑ‰ªªÂä°„ÄÅÊâìË¥•ÂØπÊâã„ÄÅËé∑ÂæóÂ•ñÂä±Á≠âÊñπÂºèÊù•ÁßØÁ¥ØËøô‰∫õÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏Å„ÄÇ\n",
            "\n",
            "2. Áé©ÂÆ∂ÈúÄË¶ÅÂ≠¶‰ºö‰∏Ä‰∫õÈ´òÁ∫ßÁâ©ÂìÅÂíåÊäÄËÉΩ„ÄÇËøô‰∫õÁâ©ÂìÅÂíåÊäÄËÉΩÂèØ‰ª•Â∏ÆÂä©Áé©ÂÆ∂Âú®Ê∏∏Êàè‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑ‰ºòÂäøÔºå‰æãÂ¶ÇÊõ¥È´òÁöÑÁîüÂëΩÂÄº„ÄÅÊõ¥È´òÁöÑÊîªÂáªÂäõ„ÄÅÊõ¥Â§öÁöÑÊäÄËÉΩÁ≠âÁ≠â„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÂØªÊâæËøô‰∫õÁâ©ÂìÅÂíåÊäÄËÉΩÁöÑË∏™ËøπÔºåÂπ∂Â≠¶‰ºö‰ΩøÁî®ÂÆÉ‰ª¨„ÄÇ\n",
            "\n",
            "3. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫â„ÄÇ‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫âÂèØ‰ª•ËÆ©Áé©ÂÆ∂Ëé∑ÂæóÊõ¥Â§öÁöÑÊ∏∏ÊàèÂ∏ÅÂíåÁªèÈ™åÂÄºÔºåÂπ∂ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÊâæÂà∞‰∏Ä‰∫õÂº∫Â§ßÁöÑÂØπÊâãÊù•Á´û‰∫âÔºåÂπ∂Âà∂ÂÆö‰∏Ä‰∫õÊúâÊïàÁöÑÁ≠ñÁï•Êù•ÂáªË¥•‰ªñ‰ª¨„ÄÇ\n",
            "\n",
            "4. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏çÊñ≠ÊåëÊàòËá™Â∑±„ÄÇÊåëÊàòËá™Â∑±ÂèØ‰ª•ËÆ©Áé©ÂÆ∂‰∏çÊñ≠ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥ÔºåÂπ∂Âú®Ê∏∏Êàè‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑ‰ºòÂäø„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÊåëÊàò‰∏Ä‰∫õÈöæÂ∫¶ËæÉÈ´òÁöÑ‰ªªÂä°ÂíåÂØπÊâãÔºåÂπ∂‰∏çÊñ≠ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥„ÄÇ\n",
            "\n",
            "5. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Âêà‰Ωú„ÄÇ‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Âêà‰ΩúÂèØ‰ª•ËÆ©Áé©ÂÆ∂Âú®Ê∏∏Êàè‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑ‰ºòÂäøÔºåÂπ∂‰∏éÂÖ∂‰ªñÁé©ÂÆ∂‰∏ÄËµ∑ÂÆåÊàê‰ªªÂä°ÂíåÊåëÊàò„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÂØªÊâæ‰∏Ä‰∫õÂº∫Â§ßÁöÑÈòüÂèãÊù•Âêà‰ΩúÔºåÂπ∂Âà∂ÂÆö‰∏Ä‰∫õÊúâÊïàÁöÑÁ≠ñÁï•Êù•ÂáªË¥•‰ªñ‰ª¨„ÄÇ\n",
            "\n",
            "‰ª•‰∏äÊòØÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑ÉÁöÑËØ¶ÁªÜÊ≠•È™§ÔºåÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏çÊñ≠ÁßØÁ¥ØÂ§ßÈáèÁöÑÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏ÅÔºåÂ≠¶‰ºö‰∏Ä‰∫õÈ´òÁ∫ßÁâ©ÂìÅÂíåÊäÄËÉΩÔºå‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫âÔºåÂπ∂‰∏çÊñ≠ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥ÔºåÊâçËÉΩÂú®Ê∏∏Êàè‰∏≠ÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑É„ÄÇ [('‰ªÄ‰πàÊòØÈò∂Á∫ßË∑≥Ë∑É,ËøòÊúâÂ¶Ç‰ΩïÁúüÊ≠£ÂÅöÂà∞Âπ∂ÁªÜËØ¥ÂÆûÁé∞Ê≠•È™§', 'Èò∂Á∫ßË∑≥Ë∑ÉÊòØÊåáÂú®‰∏Ä‰∏™Ê∏∏Êàè‰∏≠ÔºåÁé©ÂÆ∂ÈÄöËøá‰∏Ä‰∫õÊäÄÂ∑ßÂíåÁ≠ñÁï•Ôºå‰ªé‰∏Ä‰∏™ÊôÆÈÄöÁöÑÁé©ÂÆ∂Áõ¥Êé•Ë∑ÉÂèò‰∏∫È´òÁ∫ßÁé©ÂÆ∂Ôºå‰æãÂ¶Ç‰∏Ä‰∏™ÂàùÁ∫ßÁé©ÂÆ∂Âà∞È´òÁ∫ßÁé©ÂÆ∂ÁöÑÈò∂Á∫ßË∑®Ë∂ä„ÄÇ\\n\\nÈò∂Á∫ßË∑≥Ë∑ÉÈÄöÂ∏∏ÈúÄË¶ÅÁé©ÂÆ∂Âú®ÂàùÊúüÁßØÁ¥ØÂ§ßÈáèÁöÑÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏ÅÔºåÁÑ∂Âêé‰ΩøÁî®Ëøô‰∫õÁßØÁ¥ØÊù•Ë¥≠‰π∞Ê∏∏Êàè‰∏≠ÁöÑÈ´òÁ∫ßÁâ©ÂìÅÂíåÊäÄËÉΩÔºåÊàñËÄÖÂú®Ê∏∏Êàè‰∏≠‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫âÔºåÈÄöËøáÂáªË¥•ÂØπÊâãÊù•Ëé∑ÂæóÊõ¥Â§öÁöÑÊ∏∏ÊàèÂ∏ÅÂíåÁªèÈ™åÂÄº„ÄÇ\\n\\nÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑ÉÁöÑËØ¶ÁªÜÊ≠•È™§Â¶Ç‰∏ãÔºö\\n\\n1. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÁßØÁ¥ØÂ§ßÈáèÁöÑÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏Å„ÄÇÂèØ‰ª•ÈÄöËøáÂÆåÊàêÊ∏∏Êàè‰∏≠ÁöÑ‰ªªÂä°„ÄÅÊâìË¥•ÂØπÊâã„ÄÅËé∑ÂæóÂ•ñÂä±Á≠âÊñπÂºèÊù•ÁßØÁ¥ØËøô‰∫õÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏Å„ÄÇ\\n\\n2. Áé©ÂÆ∂ÈúÄË¶ÅÂ≠¶‰ºö‰∏Ä‰∫õÈ´òÁ∫ßÁâ©ÂìÅÂíåÊäÄËÉΩ„ÄÇËøô‰∫õÁâ©ÂìÅÂíåÊäÄËÉΩÂèØ‰ª•Â∏ÆÂä©Áé©ÂÆ∂Âú®Ê∏∏Êàè‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑ‰ºòÂäøÔºå‰æãÂ¶ÇÊõ¥È´òÁöÑÁîüÂëΩÂÄº„ÄÅÊõ¥È´òÁöÑÊîªÂáªÂäõ„ÄÅÊõ¥Â§öÁöÑÊäÄËÉΩÁ≠âÁ≠â„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÂØªÊâæËøô‰∫õÁâ©ÂìÅÂíåÊäÄËÉΩÁöÑË∏™ËøπÔºåÂπ∂Â≠¶‰ºö‰ΩøÁî®ÂÆÉ‰ª¨„ÄÇ\\n\\n3. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫â„ÄÇ‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫âÂèØ‰ª•ËÆ©Áé©ÂÆ∂Ëé∑ÂæóÊõ¥Â§öÁöÑÊ∏∏ÊàèÂ∏ÅÂíåÁªèÈ™åÂÄºÔºåÂπ∂ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÊâæÂà∞‰∏Ä‰∫õÂº∫Â§ßÁöÑÂØπÊâãÊù•Á´û‰∫âÔºåÂπ∂Âà∂ÂÆö‰∏Ä‰∫õÊúâÊïàÁöÑÁ≠ñÁï•Êù•ÂáªË¥•‰ªñ‰ª¨„ÄÇ\\n\\n4. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏çÊñ≠ÊåëÊàòËá™Â∑±„ÄÇÊåëÊàòËá™Â∑±ÂèØ‰ª•ËÆ©Áé©ÂÆ∂‰∏çÊñ≠ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥ÔºåÂπ∂Âú®Ê∏∏Êàè‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑ‰ºòÂäø„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÊåëÊàò‰∏Ä‰∫õÈöæÂ∫¶ËæÉÈ´òÁöÑ‰ªªÂä°ÂíåÂØπÊâãÔºåÂπ∂‰∏çÊñ≠ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥„ÄÇ\\n\\n5. Áé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Âêà‰Ωú„ÄÇ‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Âêà‰ΩúÂèØ‰ª•ËÆ©Áé©ÂÆ∂Âú®Ê∏∏Êàè‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑ‰ºòÂäøÔºåÂπ∂‰∏éÂÖ∂‰ªñÁé©ÂÆ∂‰∏ÄËµ∑ÂÆåÊàê‰ªªÂä°ÂíåÊåëÊàò„ÄÇÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠ÂØªÊâæ‰∏Ä‰∫õÂº∫Â§ßÁöÑÈòüÂèãÊù•Âêà‰ΩúÔºåÂπ∂Âà∂ÂÆö‰∏Ä‰∫õÊúâÊïàÁöÑÁ≠ñÁï•Êù•ÂáªË¥•‰ªñ‰ª¨„ÄÇ\\n\\n‰ª•‰∏äÊòØÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑ÉÁöÑËØ¶ÁªÜÊ≠•È™§ÔºåÁé©ÂÆ∂ÈúÄË¶ÅÂú®Ê∏∏Êàè‰∏≠‰∏çÊñ≠ÁßØÁ¥ØÂ§ßÈáèÁöÑÁªèÈ™åÂÄºÂíåÊ∏∏ÊàèÂ∏ÅÔºåÂ≠¶‰ºö‰∏Ä‰∫õÈ´òÁ∫ßÁâ©ÂìÅÂíåÊäÄËÉΩÔºå‰∏éÂÖ∂‰ªñÁé©ÂÆ∂Á´û‰∫âÔºåÂπ∂‰∏çÊñ≠ÊèêÈ´òËá™Â∑±ÁöÑÊ∏∏ÊàèÊ∞¥Âπ≥ÔºåÊâçËÉΩÂú®Ê∏∏Êàè‰∏≠ÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑É„ÄÇ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "Â§ñÈÉ®‰ø°ÊÅØÁºñÁ†ÅÊàê‰∏Ä‰∏™È´òÁª¥ÂêëÈáè"
      ],
      "metadata": {
        "id": "dKx53ahfSmKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #ÂÆòÊñπÁ§∫‰æã‰ª£Á†ÅÔºåÁî®ÁöÑOpenAIÁöÑadaÁöÑÊñáÊú¨EmbeddingÊ®°Âûã\n",
        "# #1Ôºâ Embeding model\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
        "# query_result = embeddings.embed_query(\"‰Ω†Â•Ω\")\n",
        "\n",
        "# #2) ÊñáÊú¨ÂàáÂâ≤\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=100, chunk_overlap=0\n",
        "# )\n",
        "# texts = \"\"\"Èò∂Á∫ßË∑≥Ë∑ÉÊòØÊåá‰∏Ä‰∏™‰∫∫Êàñ‰∏Ä‰∏™ÁªÑÁªáÈÄöËøáÊèêÈ´òËá™Â∑±ÁöÑÊäÄËÉΩ„ÄÅÁü•ËØÜÂíåÈ¢ÜÂØºËÉΩÂäõÔºå‰ªé‰∏Ä‰∏™Èò∂Á∫ßË∑®Ë∂äÂà∞Âè¶‰∏Ä‰∏™Èò∂Á∫ßÁöÑËøáÁ®ã„ÄÇË¶ÅÂÆûÁé∞Èò∂Á∫ßË∑≥Ë∑ÉÔºå‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂª∫ËÆÆÔºö\\n\\n1. Â≠¶‰π†Êñ∞ÊäÄËÉΩÔºöÂ≠¶‰π†Êñ∞ÊäÄËÉΩÂèØ‰ª•ËÆ©‰∫∫ÂÖ∑Â§áÊñ∞ÁöÑÁü•ËØÜÂíåÊäÄËÉΩÔºå‰ªéËÄåÂ¢ûÂä†Ëá™Â∑±ÁöÑÁ´û‰∫âÂäõ„ÄÇÂèØ‰ª•ÈÄâÊã©Â≠¶‰π†‰∏éÁõÆÂâçÂ∑•‰ΩúÁõ∏ÂÖ≥ÁöÑÊñ∞ÊäÄËÉΩÔºåÊàñËÄÖÂ≠¶‰π†‰∏éÊú™Êù•Â∑•‰ΩúÁõ∏ÂÖ≥ÁöÑÊñ∞ÊäÄËÉΩ„ÄÇ\\n\\n2. ÊèêÈ´òÁü•ËØÜÊ∞¥Âπ≥Ôºö‰∏çÊñ≠Â≠¶‰π†Êñ∞Áü•ËØÜÂèØ‰ª•Â¢ûÂä†Ëá™Â∑±ÁöÑÁü•ËØÜÂÇ®Â§áÔºå‰ªéËÄåÊèêÈ´òËá™Â∑±ÁöÑÁ´û‰∫âÂäõ„ÄÇÂèØ‰ª•ÈÄöËøáÈòÖËØª‰π¶Á±ç„ÄÅÂèÇÂä†ÂüπËÆ≠„ÄÅÂèÇ‰∏éÁ∫ø‰∏äËØæÁ®ãÁ≠âÊñπÂºèÊù•ÊèêÈ´òËá™Â∑±ÁöÑÁü•ËØÜÊ∞¥Âπ≥„ÄÇ\\n\\n3. Âª∫Á´ãËâØÂ•ΩÁöÑ‰∫∫ÈôÖÂÖ≥Á≥ªÔºöÂª∫Á´ãËâØÂ•ΩÁöÑ‰∫∫ÈôÖÂÖ≥Á≥ªÂèØ‰ª•ËÆ©‰∫∫Êõ¥ÂÆπÊòìÂæóÂà∞Êñ∞Êú∫‰ºöÔºåÂêåÊó∂‰πüÂèØ‰ª•Ëé∑ÂæóÊõ¥Â§öÁöÑÊîØÊåÅÂíåÂ∏ÆÂä©„ÄÇÂèØ‰ª•ÈÄöËøáÂèÇÂä†Á§æ‰∫§Ê¥ªÂä®„ÄÅÂª∫Á´ã‰∫∫ËÑâ„ÄÅÂèÇÂä†Á§æÂå∫ÁªÑÁªáÁ≠âÊñπÂºèÊù•Âª∫Á´ãËâØÂ•ΩÁöÑ‰∫∫ÈôÖÂÖ≥Á≥ª„ÄÇ\\n\\n4. ÊèêÈ´òËá™Â∑±ÁöÑÈ¢ÜÂØºËÉΩÂäõÔºöÈ¢ÜÂØºËÉΩÂäõÂèØ‰ª•ËÆ©‰∫∫Êõ¥Â•ΩÂú∞ÁÆ°ÁêÜËá™Â∑±ÁöÑÊó∂Èó¥ÂíåËµÑÊ∫êÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÂÆåÊàêÂ∑•‰Ωú„ÄÇÂèØ‰ª•ÈÄöËøáÂèÇÂä†È¢ÜÂØºÂäõËØæÁ®ã„ÄÅÂèÇÂä†Âõ¢ÈòüÂª∫ËÆæÊ¥ªÂä®„ÄÅËá™ÊàëÂèçÊÄùÁ≠âÊñπÂºèÊù•ÊèêÈ´òËá™Â∑±ÁöÑÈ¢ÜÂØºËÉΩÂäõ„ÄÇ\\n\\n5. Âª∫Á´ãËá™Â∑±ÁöÑÂìÅÁâåÔºöÂª∫Á´ãËá™Â∑±ÁöÑÂìÅÁâåÂèØ‰ª•ËÆ©‰∫∫Êõ¥ÂÆπÊòìË¢´‰∫∫ËÆ∞‰ΩèÔºå‰ªéËÄåÊõ¥ÂÆπÊòìÂæóÂà∞Êñ∞Êú∫‰ºö„ÄÇÂèØ‰ª•ÈÄöËøáÂÜôÂçöÂÆ¢„ÄÅÂèëÂ∏ÉËßÜÈ¢ë„ÄÅÂà∂‰ΩúÁΩëÁ´ôÁ≠âÊñπÂºèÊù•Âª∫Á´ãËá™Â∑±ÁöÑÂìÅÁâå„ÄÇ\\n\\nÈò∂Á∫ßË∑≥Ë∑ÉÈúÄË¶ÅÈïøÊúüÁöÑÂä™ÂäõÂíå‰∏çÊñ≠Â≠¶‰π†ÔºåÈúÄË¶ÅÂØπËá™Â∑±ÁöÑËÉΩÂäõÂíåÁõÆÊ†áÊúâÊ∏ÖÊô∞ÁöÑËÆ§ËØÜÔºåÂπ∂Âà∂ÂÆöÊòéÁ°ÆÁöÑËÆ°ÂàíÂíåÁõÆÊ†á„ÄÇ\"\"\"\n",
        "# texts = text_splitter.create_documents([texts])\n",
        "# print(texts[0].page_content)\n",
        "\n",
        "# # 3)ÂÖ•Â∫ìÊ£ÄÁ¥¢ÔºåÂÆòÊñπ‰ΩøÁî®ÁöÑPinecone,‰ªñÊèê‰æõ‰∏Ä‰∏™ÂêéÂè∞ÁÆ°ÁêÜÁïåÈù¢ | Áî®Êà∑ÈúÄÊ±ÇÂ§™Â§ßÔºå‰∏çÂ•ΩÁî®‰∫ÜÂ∑≤ÁªèÔºå‰∏ÄÁõ¥Âä†ËΩΩ‰∏≠....\n",
        "# import pinecone\n",
        "# from langchain.vectorstores import Pinecone\n",
        "# pinecone.init(api_key=os.getenv(\"\"), enviroment=os.getenv(\"\"))\n",
        "\n",
        "# index_name = \"demo\"\n",
        "# search = Pinecone.from_documents(texts=texts, embeddings, index_name=index_name)\n",
        "# query = \"What is magical about an autoencoder?\"\n",
        "# result = search.similarity_search(query)\n",
        "\n",
        "### ËøôÈáå‰ΩøÁî®chatGLM\n",
        "# 1Ôºâ Embedding model:  text2vec-large-chinese"
      ],
      "metadata": {
        "id": "odYd5qgFSnIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "\n",
        "class TextSpliter(CharacterTextSplitter):\n",
        "    def __init__(self, separator: str = \"\\n\\n\", **kwargs: Any):\n",
        "        super().__init__(separator, **kwargs)\n",
        "\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        texts = text.split(\"\\n\")\n",
        "        texts = [Document(page_content=text, metadata={\"from\": \"filename or book.txt\"}) for text in texts]\n",
        "        return texts\n",
        "\n",
        "texts = response\n",
        "\n",
        "text_splitter = TextSpliter()\n",
        "texts = text_splitter.split_text(texts)\n",
        "texts1 = [text.page_content for text in texts]\n",
        "\n",
        "texts1"
      ],
      "metadata": {
        "id": "KD-lRdx-Ynxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"GanymedeNil/text2vec-large-chinese\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': \"cuda\"})\n",
        "query_result = embeddings.embed_query(\"Èò∂Á∫ßË∑≥Ë∑É\")\n",
        "\n",
        "np.array(query_result).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLkGJuZcbPUx",
        "outputId": "55517926-9523-40b5-8e16-d170c4d61051"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vs_path = \"text_to_emb\"\n",
        "\n",
        "docs = embeddings.embed_documents(texts1)\n",
        "\n",
        "vector_store = FAISS.from_documents(texts, embeddings)\n",
        "vector_store.save_local(vs_path)\n",
        "\n",
        "vector_store = FAISS.load_local(vs_path, embeddings)\n",
        "related_docs_with_score = vector_store.similarity_search_with_score(query=\"Èò∂Á∫ßË∑≥Ë∑É\", k=2)"
      ],
      "metadata": {
        "id": "x7vw5wD6bOLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 Âü∫‰∫éÊü•ËØ¢Âà∞ÁöÑÁü•ËØÜÂÅöprompt\n",
        "context = \"\"\n",
        "for pack in related_docs_with_score:\n",
        "    doc, socre = pack\n",
        "    content = doc.page_content\n",
        "    print(\"Ê£ÄÁ¥¢Âà∞ÁöÑÁü•ËØÜ=%s, from=%s, socre=%.3f\"%(content, doc.metadata.get(\"from\"), socre))\n",
        "    context += content\n",
        "\n",
        "# ÈáçÊñ∞ÈÖçÁΩÆ‰∏Ä‰∏™Âü∫‰∫é‰∏ä‰∏ãÊñáÁöÑÊ®°ÊùøÂú®Êù•Ë∞É‰∏ãËØ≠Ë®ÄÊ®°Âûã\n",
        "template = \"Â∑≤Áü•{context}, ËØ∑ÁªôÊàëËß£Èáä‰∏Ä‰∏ã{query}ÁöÑÊÑèÊÄù?\"\n",
        "promptTem = PromptTemplate(input_variables=[\"context\", \"query\"], template=template)\n",
        "chain = DemoChain(llm=llm, prompt=promptTem)\n",
        "print(\"-\"*80)\n",
        "print(chain.run(query=\"Â§©ÈÅìÈÖ¨Âã§\", context=context))\n",
        "print(\"-\"*80)"
      ],
      "metadata": {
        "id": "J8-n7QC2dS8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### llmÈáçÂÜô\n",
        "\n",
        "TfboyLLMÁªßÊâø‰∫Ülangchain.llms.baseÁöÑLLMÁ±ª„ÄÇÈúÄË¶ÅÂÆûÁé∞ÂÆÉÁöÑ‰∏§‰∏™ÊñπÊ≥ïÔºö\n",
        "\n",
        "*   _call: ‰∏ªË¶ÅÁöÑÂ§ÑÁêÜÊñπÊ≥ïÔºåÂØπ‰º†Êù•ÁöÑpromptÈóÆÈ¢òÂàÜÊûêÔºåÁªô‰ªñ‰∏Ä‰∏™Á≠îÊ°à„ÄÇreturn\n",
        "\n",
        "*   _identifying_params: ËØ¥ÊòéLLMÁ±ª‰∏≠ÁöÑÂèÇÊï∞ÂíåÊï∞ÂÄº„ÄÇÊú¨‰æã‰∏≠Ê≤°ÊúâÁ±ªÁöÑÊàêÂëòÂèòÈáè„ÄÇ\n",
        "\n",
        "\n",
        "ÂÖ∂ÂÆûÂÖ≥ÈîÆË¶ÅÁúã_call‰∏≠ÂÆûÁé∞ÁöÑÈÄªËæëÔºö\n",
        "Êî∂Âà∞promptÂÖàÊâìÂç∞Âá∫Êù•„ÄÇ\n",
        "ÂØπÈóÆÈ¢òÊ≠£ÂàôÂåπÈÖçÔºåËßÑÂàô‰∏∫Ôºö[Êï∞Â≠ó]+[ËøêÁÆóÁ¨¶]+[Êï∞Â≠ó]„ÄÇÂåπÈÖçÂà∞ÔºåËøîÂõûËÆ°ÁÆóÁªìÊûú„ÄÇÂåπÈÖç‰∏çÂà∞ÁªßÁª≠ÊâßË°å„ÄÇ\n",
        "Âà§Êñ≠ÊúâÊ≤°Êúâ[?]„ÄÇÂ¶ÇÊûúÊúâÔºåÂàôÂØπÊñáÊú¨‰∏≠Â≠óÁ¨¶ËøõË°åÊõøÊç¢ÔºåËßÑÂàô‰∏∫ÔºöÊàë->‰Ω†, ‰Ω†->Êàë, Âêó->\"\", ?->!„ÄÇ\n",
        "Â¶ÇÊûúÈÉΩ‰∏çÁ¨¶ÂêàÔºåÂ∞±ËøîÂõûÔºö‚ÄúÂæàÊä±Ê≠âÔºåËØ∑Êç¢‰∏ÄÁßçÈóÆÊ≥ï„ÄÇÊØîÂ¶ÇÔºö1+1Á≠â‰∫éÂá†‚Äù„ÄÇ"
      ],
      "metadata": {
        "id": "6dkGGNwJ77Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "import re\n",
        "\n",
        "class TfboyLLM(LLM):\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "    ) -> str:\n",
        "        print(\"ÈóÆÈ¢ò:\",prompt)\n",
        "        pattern = re.compile(r'^.*(\\d+[*/+-]\\d+).*$')\n",
        "        match = pattern.search(prompt)\n",
        "        if match:\n",
        "            result = eval(match.group(1))\n",
        "        elif \"Ôºü\" in prompt:\n",
        "            rep_args = {\"Êàë\":\"‰Ω†\", \"‰Ω†\":\"Êàë\", \"Âêó\":\"\", \"Ôºü\":\"ÔºÅ\"}\n",
        "            result = [(rep_args[c] if c in rep_args else c) for c in list(prompt)]\n",
        "            result = ''.join(result)\n",
        "        else:\n",
        "            result = \"ÂæàÊä±Ê≠âÔºåËØ∑Êç¢‰∏ÄÁßçÈóÆÊ≥ï„ÄÇÊØîÂ¶ÇÔºö1+1Á≠â‰∫éÂá†\"\n",
        "        return result\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        return {}\n",
        "\n"
      ],
      "metadata": {
        "id": "4GQgTpN_7xyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = TfboyLLM()\n",
        "print(\"Á≠îÊ°à:\",llm(\"ÊàëËÉΩÈóÆ‰Ω†ÈóÆÈ¢òÂêóÔºü\"))"
      ],
      "metadata": {
        "id": "6-ra4sWw8AnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9YP_o9wKSlNl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXVHgVjC10TvuwtkgnKE9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}